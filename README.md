# FMNIST 48Ã—48 â€” Teacher âœ Student Distillation (TFLite + C array)

**Purpose**
This repo shows how to train a compact CNN on **Fashion-MNIST (48Ã—48)** as a **teacher**, distill it into a **small student**, quantize to **INT8**, and export a **C array** for embedded use (e.g., RIOT OS).

There are also **zip files with pictures of people**. Theoretically, you could use the same pipeline to make a small camera with a microcontroller that counts how many people are in a shot. However, since there are not that many pictures, you may need to change the pipeline a bit. A `count.json` is included with placeholders (`null`) for all picture labels.

---

## ğŸ“‚ Repo Contents

* **`fashion_mnist_48_cnn_fast_v3_compat.py`**
  Teacher training script (â‰ˆ2Ã— params vs the minimal version).

* **`distill_fmnist_48_manual_v2.py`**
  Student training with **knowledge distillation (KD)**.

  * Combines cross-entropy and KD loss.
  * Converts to **INT8 TFLite** and exports a **C array**.
  * Teacher model is loaded automatically from:

    1. `./fm_48_fast_out_v3/best.keras`
    2. `./fm_48_fast_out_v2/best.keras`
    3. `./fm_48_fast_out/best.keras`

* **`make_c_array.py`**
  Standalone fallback: converts a `.tflite` model into a C array (`model_data.cc`).

* **`people_pics_*.zip`**
  Example dataset for people-counting.

  * Includes `count.json` (all labels `null` by default).
  * Can be annotated with the number of people per image and reused with a similar pipeline.

---

## ğŸš€ Quick Start

### 1. Train the Teacher

```bash
python3 FashionMnistCNN.py
```

### 2. Distill into a Student

```bash
python3 CNNDistillRIOT.py
```

Produces:

* `student_kd.keras`
* `student_int8.tflite`
* `model_data.cc`

### 3. (Optional fallback) Generate `model_data.cc` manually

If bugs occur during Step 2â€™s export:

```bash
python3 WeightsForRIOT.py
```

### 4. Deploy in RIOT OS

Copy `model_data.cc` into your RIOT project and link against TensorFlow Lite Micro.

---

## âš¡ Notes

* Teacher: \~89% accuracy on FMNIST (48Ã—48)
* Student: \~85% accuracy (INT8, distilled)
* For people-counting, pipeline is theoretically the same, but dataset size may require tweaks.

ğŸ§® Loss functions (teacher & student)
Teacher training (fashion_mnist_48_cnn_fast_v3_compat.py)

Objective: smoothed cross-entropy on 10-class Fashion-MNIST.

Loss: label-smoothed categorical cross-entropy (via one-hot)

ğ‘¦
~
â€…â€Š
=
â€…â€Š
(
1
âˆ’
ğœ€
)
â€‰
o
n
e
h
o
t
(
ğ‘¦
)
â€…â€Š
+
â€…â€Š
ğœ€
ğ¾
â€‰
1
withÂ 
ğœ€
=
0.05
,
â€…â€Š
ğ¾
=
10
y
~
	â€‹

=(1âˆ’Îµ)onehot(y)+
K
Îµ
	â€‹

1withÂ Îµ=0.05,K=10
ğ¿
teacher
â€…â€Š
=
â€…â€Š
C
E
â€‰â£
(
ğ‘¦
~
,
â€‰
ğ‘
ğœƒ
)
L
teacher
	â€‹

=CE(
y
~
	â€‹

,p
Î¸
	â€‹

)

where $\mathbf{p}_{\theta}$ are the model softmax outputs.

In code: smooth_sparse_cce(num_classes=10, label_smoothing=0.05) â†’ keras.losses.categorical_crossentropy

Optimizer: Adam (lr = 1e-3)

Regularization: L2 (1e-4) on conv/dense kernels

Augmentations: pad+random crop, light brightness/contrast jitter

Student distillation (distill_fmnist_48_manual_v2.py)

Objective: combine hard-label CE with a temperature-scaled KD term from the frozen teacher.

Hard-label term (student logits $\mathbf{z}_s$):

ğ¿
CE
â€…â€Š
=
â€…â€Š
C
E
sparse
â€‰â£
(
ğ‘¦
,
â€‰
ğ‘§
ğ‘ 
)
L
CE
	â€‹

=CE
sparse
	â€‹

(y,z
s
	â€‹

)

(implemented with SparseCategoricalCrossentropy(from_logits=True))

KD term (teacher probs $\mathbf{p}_t$):

ğ‘
ğ‘¡
(
ğ‘‡
)
â€…â€Š
=
â€…â€Š
n
o
r
m
â€‰â£
(
ğ‘
ğ‘¡
â€‰
1
/
ğ‘‡
)
,
ğ‘
ğ‘ 
(
ğ‘‡
)
â€…â€Š
=
â€…â€Š
s
o
f
t
m
a
x
â€‰â£
(
ğ‘§
ğ‘ 
/
ğ‘‡
)
p
t
(T)
	â€‹

=norm(p
t
1/T
	â€‹

),p
s
(T)
	â€‹

=softmax(z
s
	â€‹

/T)
ğ¿
KD
â€…â€Š
=
â€…â€Š
ğ‘‡
2
â‹…
K
L
â€‰â£
(
ğ‘
ğ‘¡
(
ğ‘‡
)
â€‰
âˆ¥
â€‰
ğ‘
ğ‘ 
(
ğ‘‡
)
)
L
KD
	â€‹

=T
2
â‹…KL(p
t
(T)
	â€‹

	â€‹

p
s
(T)
	â€‹

)

Total loss:

ğ¿
student
â€…â€Š
=
â€…â€Š
ğ›¼
â€‰
ğ¿
CE
â€…â€Š
+
â€…â€Š
(
1
âˆ’
ğ›¼
)
â€‰
ğ¿
KD
withÂ 
ğ›¼
=
0.5
,
â€…â€Š
ğ‘‡
=
3.0
L
student
	â€‹

=Î±L
CE
	â€‹

+(1âˆ’Î±)L
KD
	â€‹

withÂ Î±=0.5,T=3.0

Optimizer: Adam (lr = 1e-3)

Notes: Teacher outputs are coerced to probabilities (softmax applied if needed). KD uses the standard $T^2$ scaling.

Quantization (export path)

Full-integer INT8 conversion using a representative dataset (up to 500 samples), with inference_input_type = int8 and inference_output_type = int8.

Outputs:

student_kd.keras â€” Keras checkpoint

student_int8.tflite â€” quantized model

model_data.cpp â€” C array (g_model, g_model_len) for embedded targets (e.g., RIOT OS)
